---
title: "RNN-Based Sentiment Analysis"
slug: "/aaronradlicki/course-project"
date: 2025-11-10
author: Aaron Radlicki
description: "My submission for the ..."
tags:
  - course project
---

<table>
  <caption>
    Course Project Info
  </caption>
<tbody>
  <tr>
    <th>Code Repository URL</th>
    <td>https://github.com/uazhlt-ms-program/ling-582-fall-2025-course-project-code-feelingsentimental</td>
  </tr>
  <tr>
    <th>Demo URL (optional)</th>
    <td></td>
  </tr>
  <tr>
    <th>Team name</th>
    <td>FeelingSentimental</td>
  </tr>
</tbody>
</table>

## Mid-Semester Proposal

For my course project, I am planning to train an RNN-based PyTorch project to evaluate the valence of a set of Tweets using the popular Sentiment140 dataset.

There are several reasons why I am interested in this type of project:
* For LING 539, we did a project comparing movie reviews and I did a strictly non-neural network approach.  I would like to apply that type of approach to a similar project.  This dataset is the perfect opportunity.
* As someone who wants to work with underresourced language groups, with very small datasets, I plan to experiment on seeing how small of a training set I can work with for the purposes of this project in order to achieve relatively solid results.  (This will require multiple runs and writing a program that is able to variably slice the training data.)
* Given my research paper analysis's discussion on the complexities of code-mixing, slang-usage, and dialectical differences, I feel that it would be quite intriguing to work with this kind of a dataset and see how those factors can affect the process.

As a result, my official proposal is as follows:
*I plan to design a configurable and retrainable RNN-based PyTorch project to utilize and make predictions on the Sentiment140 dataset.  I will make at least 5 sets of predictions, with the goal being to utilize the smallest amount of training data possible while balancing a relatively high F1 score.  Cursory analysis will be provided for the initial runs, with an in-depth analysis and instructions provided to replicate the one that meets the goal of balancing a high F1 score with a lower amount of training data.  This project will be downloadable from the course GitHub repository (see above), with instructions provided below by the end of the semester.  Through this, I will be exploring the balance of dataset scope as it relates to successful NLP analysis.*

Dates:
* Dataset downloaded and scoped out by 11/23
* Working code for dataset analysis by 11/30
* Optimal configuration found by 12/7
* Writeup completed by course deadline



\-\-\- The section below will be used for my final project write-up at the end of the semester. \-\-\-



## Project description

_See [the rubric](https://parsertongue.org/courses/snlp-2/assignments/rubrics/course-project/final/#reproducibility).  Use subsections to organize components of the description._


## Summary of individual contributions
<table>
  <thead>
  <tr>
    <th>Team member</th>
    <th>Role/contributions</th>
  </tr>
  </thead>
<tbody>
  <tr>
    <th><b>???</b></th>
    <td>???</td>
  </tr>
  <tr>
    <th><b>???</b></th>
    <td>???</td>
  </tr>
  <tr>
    <th><b>???</b></th>
    <td>???</td>
  </tr>
</tbody>
</table>


## Results

_See [the rubric](https://parsertongue.org/courses/snlp-2/assignments/rubrics/course-project/final/#results)_

## Error analysis

_See [the rubric](https://parsertongue.org/courses/snlp-2/assignments/rubrics/course-project/final/#error-analysis)_

## Reproducibility

_See [the rubric](https://parsertongue.org/courses/snlp-2/assignments/rubrics/course-project/final/#reproducibility)_
_If you'ved covered this in your code repository's README, you can simply link to that document with a note._

## Future improvements

_See [the rubric](https://parsertongue.org/courses/snlp-2/assignments/rubrics/course-project/final/#proposal-for-future-improvements)_