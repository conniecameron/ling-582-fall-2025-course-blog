---
title: "Evaluating Open-Source Decoder-Only Language Models on Text Generation Tasks"
slug: "/pranithachilvari/course-project"
date: 2025-11-16
author: "Pranitha Chilvari"
description: "Proposal for my course project comparing decoder-only LLMs on controlled text generation."
tags:
  - course project
  - language models
  - decoder-only transformers
---

## Introduction

For my course project, our two-person team will conduct a structured comparison of several *open-source decoder-only large language models*.  
We plan to examine how models such as *GPT-2, **GPT-NeoX, and **Llama-2-7B-Chat* behave when given the same text generation prompts.  
Our focus is on qualitative differences in output quality, rather than training new models.

## Project Objectives

Our project has four main goals:

- Evaluate how different decoder-only architectures handle creative text continuation.  
- Compare models based on fluency, coherence, creativity, and factual reliability.  
- Identify recurring patterns such as hallucinations, repetition, or stylistic tendencies.  
- Produce an organized set of prompts + generated outputs for analysis.

This work aligns with statistical NLP by exploring model behavior through controlled prompting and systematic comparison.

## Planned Approach

We will follow a simple and repeatable process:

1. *Build a set of 12–15 prompts*, including narrative openings, conversational turns, and factual questions.  
2. *Query each model* using consistent generation settings like temperature, max tokens, etc.  
3. *Collect and organize outputs* in a structured format for side-by-side comparison.  
4. *Evaluate each output* along several qualitative dimensions:
   - Grammar and fluency  
   - Logical flow  
   - Creativity or richness  
   - Accuracy  
   - Presence of bias or toxicity  
5. *Write a comparative analysis* highlighting strengths and weaknesses across models.

## Timeline (Starting November 17)

- *Nov 17–20:* Create the prompt set, finalize model selection  
- *Nov 21–26:* Run all prompts through each model and save outputs  
- *Nov 27–Dec 2:* Perform qualitative evaluation of model responses  
- *Dec 3–Dec 6:* Draft comparison tables and write analysis  
- *Dec 7–Dec 10:* Complete write-up and open PR for course blog submission

## Project Repository

We will upload prompts, outputs, and analysis materials to a shared GitHub Classroom repository.

https://github.com/uazhlt-ms-program/ling-582-fall-2025-course-project-code-pranitha-chandana.git 

## Team Members & Contributions

- *Chandana:* Designing the prompt set, organizing model outputs, writing the main analysis section  
- *Pranitha:* Running prompts through each model, assembling evaluation tables, assisting with the final write-up
